"""
Student Grade Prediction using KNN, SVM, and Random Forest

- Feature scaling and model evaluation
- Hyperparameter tuning with GridSearchCV
- Performance comparison with visualisation
- Confusion matrix and ROC curve for best models

Author: Finley Michael Mbella
"""

# Imports 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, roc_curve, roc_auc_score
)

# Load & Prepare Data 
# Replace with your actual data file
# data = pd.read_csv('student-math.csv')
# Example transformation: data['G3'] = (data['G3'] >= 10).astype(int)

X = data[['G1', 'G2']]  # Input features: first two grading periods
y = data['G3']          # Target: final grade (can be binarised if needed)

# Train-test split and feature scaling
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Evaluation Helper
def evaluate_model(y_true, y_pred, model_name):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')
    recall = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')
    print(f"\n{model_name} Performance:")
    print(f"Accuracy:  {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall:    {recall:.4f}")
    print(f"F1 Score:  {f1:.4f}")
    return accuracy, precision, recall, f1

# Model 1: K-Nearest Neighbours
knn_model = KNeighborsClassifier(n_neighbors=7, weights='distance', p=2)
knn_model.fit(X_train, y_train)
y_pred_knn = knn_model.predict(X_test)
knn_metrics = evaluate_model(y_test, y_pred_knn, "K-Nearest Neighbours")

# Model 2: Support Vector Machine
svm_model = SVC(kernel='rbf', gamma=0.1, C=10)
svm_model.fit(X_train, y_train)
y_pred_svm = svm_model.predict(X_test)
svm_metrics = evaluate_model(y_test, y_pred_svm, "Support Vector Machine")

# Model 3: Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
rf_metrics = evaluate_model(y_test, y_pred_rf, "Random Forest")

# Visualise Model Performance
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
model_names = ['KNN', 'SVM', 'Random Forest']
results = [knn_metrics, svm_metrics, rf_metrics]
colors = ['#e74c3c', '#3498db', '#2ecc71']
bar_width = 0.25

plt.figure(figsize=(10, 6))
for i, scores in enumerate(results):
    plt.bar(np.arange(len(metrics)) + i * bar_width, scores, width=bar_width,
            label=model_names[i], color=colors[i], alpha=0.7)
    for j, score in enumerate(scores):
        plt.text(j + i * bar_width, score + 0.02, f"{score:.2f}", ha='center', fontsize=9)

plt.xticks(np.arange(len(metrics)) + bar_width, metrics)
plt.ylabel('Score')
plt.title('Model Performance Comparison')
plt.ylim(0, 1.1)
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.4)
plt.tight_layout()
plt.show()

# Hyperparameter Tuning for KNN
param_grid = {
    'n_neighbors': [3, 5, 7, 9],
    'weights': ['uniform', 'distance'],
    'p': [1, 2]
}

grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)

print("\nBest KNN Hyperparameters:")
print(grid_search.best_params_)

best_knn = grid_search.best_estimator_
y_pred_best_knn = best_knn.predict(X_test)
evaluate_model(y_test, y_pred_best_knn, "Tuned KNN")

# Confusion Matrix for Best KNN
conf_matrix = confusion_matrix(y_test, y_pred_best_knn)
print("\nClassification Report (Best KNN):")
print(classification_report(y_test, y_pred_best_knn))

plt.figure(figsize=(6, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix – Tuned KNN')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

# ROC Curve for Random Forest (Binary Only) 
if len(np.unique(y_test)) == 2:
    y_proba_rf = rf_model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_proba_rf)
    auc_score = roc_auc_score(y_test, y_proba_rf)

    plt.figure(figsize=(7, 5))
    plt.plot(fpr, tpr, label=f"AUC = {auc_score:.2f}", color='darkorange')
    plt.plot([0, 1], [0, 1], linestyle='--', color='grey')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve – Random Forest')
    plt.legend(loc='lower right')
    plt.grid(alpha=0.4)
    plt.tight_layout()
    plt.show()
else:
    print("\nROC Curve skipped: Multiclass classification detected.")